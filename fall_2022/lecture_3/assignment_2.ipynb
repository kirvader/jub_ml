{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1186ce32",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f61ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e1d1e",
   "metadata": {},
   "source": [
    "## Task 1 (20 points)\n",
    "\n",
    "Under what assumption Decision Tree performes worse than Linear Regression?  \n",
    "Create a dataset, choose train/test split, and make experiment to support the claim.  \n",
    "Use `sklearn.linear_model.LinearRegression`, `sklearn.tree.DecisionTreeRegressor`, `sklearn.datasets.make_regression`  \n",
    "Use MSE loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70171a49",
   "metadata": {},
   "source": [
    "## Task 2 (20 points)\n",
    "Make dataset preprocessing as described below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe159eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2bfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "del df['id']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['month'].map({'January':1, 'February':2, 'March': 3, 'April': 4, \n",
    "                               'May':5, 'June':6, 'July':7, 'August':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3149a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credit_history_age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9008cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert column into number of months (float). Fill missing data with 0\n",
    "\n",
    "df['credit_history_age'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ec853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type_of_loan'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c12630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO type_of_loan is a combination of flags\n",
    "# for each type of loan create a seperate colum with binary values.\n",
    "# fill missing data with 0\n",
    "\n",
    "loan_types = ..\n",
    "for col in loan_types:\n",
    "    col_name = col.replace(' ', '_')\n",
    "    df[col_name] = ...\n",
    "    \n",
    "del df['type_of_loan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d5fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = [\n",
    "    'monthly_inhand_salary',\n",
    "    'num_of_delayed_payment',\n",
    "    'num_credit_inquiries',\n",
    "    'credit_history_age',\n",
    "    'amount_invested_monthly',\n",
    "    'monthly_balance'\n",
    "]\n",
    "\n",
    "# TODO replace missing values in the columns with an average over values with the same client_id \n",
    "# If all values within the same client_id are missing, replace them with an average over entire column\n",
    "\n",
    "for col in tqdm(nan_columns): \n",
    "    df[col] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_columns = [\n",
    "            'customer_id', 'name', 'credit_score', 'payment_behaviour', 'occupation', 'ssn', \n",
    "            'payment_of_min_amount', 'credit_mix', \n",
    "        ]\n",
    "\n",
    "# TODO encode column values with integers. Use sklearn.preprocessing.LabelEncoder\n",
    "\n",
    "for col in ctg_columns:\n",
    "    df[col] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace('_', '')\n",
    "        if len(x) > 0:\n",
    "            return float(x)\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return float(x)\n",
    "    \n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all(pd.isnull(df).sum() == 0) and np.isnan(df.values.astype(float)).sum():\n",
    "    print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe570a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['month'] == 8].reset_index(drop=True)\n",
    "df_train = df[df['month'] != 8].reset_index(drop=True)\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = df_test.drop(columns='credit_score').values, df_test['credit_score'].values\n",
    "X_train, y_train = df_train.drop(columns='credit_score').values, df_train['credit_score'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee465b",
   "metadata": {},
   "source": [
    "## Task 3 (20 points)\n",
    "Fit Random Forest Classifier on the dataset.  \n",
    "Implement grid search with some cross-validation schema to select hyperparams for Random Forest.  \n",
    "Surpass baseline F1_macro = 0.72 on the test subset  \n",
    "Tune only most sensitive hyperparams, consider your computational budget.  \n",
    "\n",
    "Note: you cannot use sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp1_space = ...\n",
    "...\n",
    "hypk_space = ...\n",
    "\n",
    "records = []\n",
    "\n",
    "\n",
    "for train, valid in split(X_train, y_train, ...):\n",
    "    \n",
    "    for hyp1_value in hyp1_space:\n",
    "        ...\n",
    "        for hypk_value in hypk_space:\n",
    "            ...\n",
    "            model = ensemble.RandomForestClassifier(...)\n",
    "            model.fit(...)\n",
    "            y_pred = model.predict(X_test)\n",
    "            score = metrics.f1_score(y_valid, y_pred, average='macro')\n",
    "            records.append({'hyp1': hyp1, ..., 'hypk': hypk,  'score': score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18816fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.DataFrame(records)\n",
    "records.groupby(['hyp1', ... ,'hypk']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = ...\n",
    "\n",
    "# don't forget to retrain model on the whole train dataset\n",
    "\n",
    "y_pred = model.predict(...)\n",
    "score = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "if score >= 0.72:\n",
    "    print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538ad65",
   "metadata": {},
   "source": [
    "## Task 4 (20 points)\n",
    "\n",
    "Fit XGBoost classifier on the dataset.  \n",
    "Implement grid search with hold-out validation schema to select hyperparams.  \n",
    "Surpass baseline F1_macro = 0.73 on the test subset  \n",
    "Tune only most sensitive hyperparams, consider your computational budget.  \n",
    "\n",
    "Note: use additional arguments (eval_metric, eval_set) in XGBoost classifier to make early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d141b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp1_space = ...\n",
    "...\n",
    "hypk_space = ...\n",
    "\n",
    "records = []\n",
    "\n",
    "train, valid = split(X_train, y_train, ...):\n",
    "    \n",
    "for hyp1_value in hyp1_space:\n",
    "    ...\n",
    "    for hypk_value in hypk_space:\n",
    "        ...\n",
    "        model = xgb.XGBClassifier(...)\n",
    "        model.fit(...)\n",
    "        y_pred = model.predict(...)\n",
    "        score = metrics.f1_score(y_valid, y_pred, average='macro')\n",
    "        records.append({'hyp1': hyp1, ..., 'hypk': hypk,  'score': score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a354fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.DataFrame(records)\n",
    "records.loc[records['score'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de556a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = ...\n",
    "\n",
    "# don't forget to retrain model on the whole train dataset\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "score = metrics.f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "if score >= 0.73:\n",
    "    print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691159ea",
   "metadata": {},
   "source": [
    "## Task 5 (20 points)\n",
    "\n",
    "How feature importance is connected to the underlying model?   \n",
    "Select top 10 most important features from Logistic Regression and Random Forest.   \n",
    "On these selected features fit logistic regression with L2 norm regularization and some fixed regularization coefficient.  \n",
    "Which selected features are better in terms of F1_macro score?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043a729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
